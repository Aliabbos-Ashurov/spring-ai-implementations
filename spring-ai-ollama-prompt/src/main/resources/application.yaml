spring:
  application:
    name: spring-ai-ollama-chat
  ai:
    ollama:
      base-url: http://localhost:11434
      chat:
        model: llama3
      init:
        timeout: 60s
    openai:
      api-key: ${OLLAMA_API_KEY}
server:
  port: 8084
springdoc:
  api-docs:
    enabled: true